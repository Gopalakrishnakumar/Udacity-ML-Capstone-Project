{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-562840379c4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcategorical_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_crossentropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mNCATS\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m340\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.metrics import categorical_accuracy, categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "\n",
    "NUM_CATS= 340\n",
    "BASE_SIZE=256\n",
    "size=64\n",
    "imgs_per_class=2000\n",
    "Train_path = 'train_simplified/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_files = os.listdir(Train_path)\n",
    "print(category_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [file.replace('.csv','') for file in category_files]\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "word_encoder = LabelEncoder()\n",
    "word_encoder.fit(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for i in range(2):\n",
    "    print('Class',category_files[i])\n",
    "    file = os.path.join(Train_path,category_files[i])\n",
    "    file = pd.read_csv(file)\n",
    "    file=file[:20]\n",
    "    file['drawing']=file['drawing'].apply(ast.literal_eval)\n",
    "    fig, axs = plt.subplots(2, 10, figsize=(16, 3))\n",
    "    for j,drawing in enumerate(file.drawing):\n",
    "        ax = axs[j // 10, j % 10]\n",
    "        for x,y in drawing:\n",
    "            #print('x: ',x)\n",
    "            #print('y: ',y)\n",
    "            ax.plot(x,-np.array(y));\n",
    "        ax.axis('off');\n",
    "        #vector = np.matrix(drawing)\n",
    "        #print(vector)\n",
    "        #arr2 = np.asarray(vector).reshape(arr.shape)\n",
    "        \n",
    "        # make a PIL image\n",
    "        #img2 = Image.fromarray(arr2, 'RGBA')\n",
    "        #img2.show()\n",
    "    plt.show()\n",
    "    #print(np.stack(file['drawing'],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=[]\n",
    "for file in category_files:\n",
    "    df = pd.read_csv(os.path.join(Train_path, file))\n",
    "    count.append(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorised_count=[]\n",
    "categorised_count.append(len([x for x in count if x<150000]))\n",
    "categorised_count.append(len([x for x in count if 200000>x>150000]))\n",
    "categorised_count.append(len([x for x in count if 200000<x<250000]))\n",
    "categorised_count.append(len([x for x in count if 250000<x<300000]))\n",
    "categorised_count.append(len([x for x in count if 300000<x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(8,8))\n",
    "plt.bar(['<1.5L','1.5L-2L','2L-2.5L','2.5L-3L','>3L'],categorised_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file = os.path.join(Train_path,category_files[0])\n",
    "file = pd.read_csv(file)\n",
    "file['drawing'] = file['drawing'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def convert_df_array(raw_strokes,size=256,lw=5,time_color=True):\n",
    "    image = np.zeros((BASE_SIZE,BASE_SIZE),np.uint8)\n",
    "    for i,stroke in enumerate(raw_strokes):\n",
    "        for j in range(len(stroke[0])-1):\n",
    "            color = 255-min(i,10)*13 if time_color else 255\n",
    "            cv2.line(image,(stroke[0][j],stroke[1][j]),\n",
    "                     (stroke[0][j+1],stroke[1][j+1]),color,lw)\n",
    "    if size != BASE_SIZE:\n",
    "        return cv2.resize(image, (size, size))\n",
    "    else:\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_image_array_xd(df, size, lw=6, time_color=True):\n",
    "    df['drawing'] = df['drawing'].apply(json.loads)\n",
    "    x = np.zeros((len(df), size, size, 1))\n",
    "    for i, raw_strokes in enumerate(df.drawing.values):\n",
    "        x[i, :, :, 0] = convert_df_array(raw_strokes, size=size, lw=lw, time_color=time_color)\n",
    "    x = preprocess_input(x).astype(np.float32)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator_xd(size, batchsize, ks, lw=6, time_color=True):\n",
    "    while True:\n",
    "        for k in np.random.permutation(ks):\n",
    "            filename = os.path.join(Train_path,category_files[k])\n",
    "            for df in pd.read_csv(filename, chunksize=batchsize):\n",
    "                df['drawing'] = df['drawing'].apply(json.loads)\n",
    "                x = np.zeros((len(df), size, size, 1))\n",
    "                for i, raw_strokes in enumerate(df.drawing.values):\n",
    "                    x[i, :, :, 0] = convert_df_array(raw_strokes, size=size, lw=lw,\n",
    "                                             time_color=time_color)\n",
    "                x = preprocess_input(x).astype(np.float32)\n",
    "                y = keras.utils.to_categorical(word_encoder.transform(df.word.values), num_classes=NCATS)\n",
    "                yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv(os.path.join(Train_path, category_files[0]), nrows=34000)\n",
    "x_valid = df_to_image_array_xd(valid_df, size)\n",
    "y_valid = keras.utils.to_categorical(word_encoder.transform(valid_df.word.values), num_classes=NCATS)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print('Validation array memory {:.2f} GB'.format(x_valid.nbytes / 1024.**3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image_generator_xd(size=size, batchsize=680, ks=range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(train_datagen)\n",
    "n = 8\n",
    "fig, axs = plt.subplots(nrows=n, ncols=n, sharex=True, sharey=True, figsize=(12, 12))\n",
    "for i in range(n**2):\n",
    "    ax = axs[i // n, i % n]\n",
    "    (-x[i]+1)/2\n",
    "    ax.imshow((-x[i, :, :, 0] + 1)/2, cmap=plt.cm.gray)\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "fig.savefig('gs.png', dpi=300)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "x, y = next(train_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNet(input_shape=(size, size, 1), alpha=1., weights=None, classes=NCATS)\n",
    "model.compile(optimizer=Adam(lr=0.002), loss='categorical_crossentropy',\n",
    "              metrics=[categorical_crossentropy, categorical_accuracy])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True,save_weights_only=True)\n",
    "\n",
    "model.fit_generator(train_data_gen, validation_data=(x_valid, y_valid), epochs=70, callbacks=[checkpointer], \n",
    "          steps_per_epoch=800, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
